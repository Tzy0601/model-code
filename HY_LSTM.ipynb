{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-07T08:50:59.759037Z",
     "start_time": "2024-08-07T08:50:59.743410Z"
    }
   },
   "source": [
    "# 导入必要的库\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout\n",
    "import pandas as pd\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tool import evalIndicator"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dense, Dropout\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mwrappers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mscikit_learn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KerasRegressor\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GridSearchCV\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pyplot \u001B[38;5;28;01mas\u001B[39;00m plt\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'keras.wrappers'"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "# 读取数据，划分数据集\n",
    "df = pd.read_csv(\"/Users/datou/PycharmProjects/model/HengyangSta/HY_data/衡阳站降雨径流.csv\", parse_dates=[\"Date\"])\n",
    "df_copy=df\n",
    "df.reset_index(drop=True)\n",
    "df=df.set_index('Date')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-07T08:48:47.105130Z",
     "start_time": "2024-08-07T08:48:46.646017Z"
    }
   },
   "id": "4ce21424d7786605",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/datou/PycharmProjects/model/HengyangSta/HY_data/衡阳站降雨径流.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 读取数据，划分数据集\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/Users/datou/PycharmProjects/model/HengyangSta/HY_data/衡阳站降雨径流.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparse_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDate\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m df_copy\u001B[38;5;241m=\u001B[39mdf\n\u001B[0;32m      4\u001B[0m df\u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32mc:\\users\\10673\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[0;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[0;32m    310\u001B[0m     )\n\u001B[1;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mc:\\users\\10673\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    665\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    666\u001B[0m     dialect,\n\u001B[0;32m    667\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    676\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    677\u001B[0m )\n\u001B[0;32m    678\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\10673\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    572\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    574\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 575\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    578\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32mc:\\users\\10673\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    930\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    932\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 933\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\10673\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1213\u001B[0m     mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1214\u001B[0m \u001B[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001B[39;00m\n\u001B[0;32m   1215\u001B[0m \u001B[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[39;00m\n\u001B[0;32m   1216\u001B[0m \u001B[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[39;00m\n\u001B[1;32m-> 1217\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[call-overload]\u001B[39;49;00m\n\u001B[0;32m   1218\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1219\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1220\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1223\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1224\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1225\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1226\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1227\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1228\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32mc:\\users\\10673\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\common.py:789\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    784\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    785\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    786\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    787\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    788\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 789\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    790\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    791\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    792\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    793\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    794\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    795\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    797\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    798\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/Users/datou/PycharmProjects/model/HengyangSta/HY_data/衡阳站降雨径流.csv'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "n_past=15"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b30877573f8a280",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 划分数据\n",
    "test_split = round(len(df) * 0.30)\n",
    "df_for_training = df[:-test_split]\n",
    "df_for_testing = df[-(test_split+n_past):]\n",
    "df_for_training.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "303d759021c9b182",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 数据归一化\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_for_training_scaled = scaler.fit_transform(df_for_training)\n",
    "df_for_testing_scaled = scaler.transform(df_for_testing)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f5fcee69627cb1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 创建数据集，n_past：时间步长\n",
    "def createXY(dataset, n_past):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(n_past, len(dataset)):\n",
    "        dataX.append(dataset[i - n_past:i, 0:dataset.shape[1]])\n",
    "        dataY.append(dataset[i, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "659d952f22cbc9be",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "网络中的第一层必须定义预期输入数。输入必须是三维的，由Samples、Timesteps和Features组成。\n",
    "Samples：数据中的行\n",
    "Timesteps：特征的过去观测值\n",
    "features：数据中的列\n",
    "\"\"\"\n",
    "# 这里使用30，意味着将使用过去的30个值(包括目标列在内的所有特性)来预测第31个目标值。\n",
    "trainX, trainY = createXY(df_for_training_scaled, n_past)\n",
    "trainX.shape, trainY.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f03fc2d88adb9c9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "testX, testY = createXY(df_for_testing_scaled, n_past)\n",
    "testX.shape, testY.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ca415395ea6a487",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 建立模型\n",
    "def build_model():\n",
    "    \"\"\"\n",
    "    1、定义网络\n",
    "    \"\"\"\n",
    "    grid_model = Sequential()  # 层次模型\n",
    "    \"\"\"\n",
    "    指定input_shape，该参数需要包含时间步长数和特征数的元组。\n",
    "    input_shape=(时间步长数，特征数元组)：\n",
    "    此处采用时间步长数30，特征数元组长度为2\n",
    "    LSTM 图层可以通过将它们添加到顺序模型来堆叠。\n",
    "    重要的是，在堆叠 LSTM 图层时，我们必须为每个输入输出一个序列而不是单个值，以便后续 LSTM 图层可以具有所需的 3D 输入。\n",
    "    通过将\"return_sequences true\"实现\n",
    "    \"\"\"\n",
    "    grid_model.add(LSTM(50, return_sequences=True, input_shape=(n_past, 2)))\n",
    "    \"\"\"\n",
    "    第一步是创建顺序类的实例。然后，创建图层，并按应连接它们的顺序添加它们。\n",
    "    由内存单元组成的LSTM循环层称为LSTM（）。\n",
    "    通常跟随 LSTM 图层并用于输出预测的完全连接层称为 Dense（）。\n",
    "    \"\"\"\n",
    "    grid_model.add(LSTM(100))\n",
    "    grid_model.add(Dropout(0.01))\n",
    "    grid_model.add(Dense(1))\n",
    "    learning_rate = 1e-3\n",
    "    \"\"\"\n",
    "    编译网络：编译需要指定许多参数，这些参数是专为培训网络而定制的。具体来说，用于训练网络和用于评估优化算法最小化的网络的优化算法。\n",
    "    model.compile(optimizer,loss)\n",
    "    \"\"\"\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    grid_model.compile(loss='mse', optimizer=optimizer)\n",
    "    return grid_model\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c41af0faf73eae64",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 交叉搜索，寻求模型最佳参数，并输出最佳模型\n",
    "parameters = {'batch_size': [16, 20],\n",
    "              'epochs': [16, 20]}\n",
    "\"\"\"\n",
    "verbose参数设置为 2，可以将显示的信息量减小到每轮训练的损失。\n",
    "可以通过将verbose设置为 1 来关闭所有输出\n",
    "\"\"\"\n",
    "# grid_model = KerasRegressor(build_fn=build_model, verbose=1, validation_data=(testX, testY))\n",
    "grid_model = KerasRegressor(build_fn=build_model, verbose=1)\n",
    "grid_search = GridSearchCV(estimator=grid_model, param_grid=parameters,\n",
    "                           cv=5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e789410a5b52473d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "训练网络\n",
    "\"\"\"\n",
    "grid_search = grid_search.fit(trainX, trainY)\n",
    "# 将最佳模型保存在my_model变量中\n",
    "my_model = grid_search.best_estimator_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc6db54cfa144cbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "进行预测：测试集\n",
    "\"\"\"\n",
    "prediction = my_model.predict(testX)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba855d98a7200ad5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "grid_search.best_params_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9b21726336874a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "进行预测：训练集\n",
    "\"\"\"\n",
    "train_predict=my_model.predict(trainX)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3119e06bdba94c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 逆缩放过程\n",
    "# 改变形状来进行逆缩放，逆变换后的第一列是我们需要的，所以我们在最后使用了 → [:,0]。\n",
    "prediction_copies_array = np.repeat(prediction, 2, axis=-1)\n",
    "pred = scaler.inverse_transform(np.reshape(prediction_copies_array, (len(prediction), 2)))[:, 0]\n",
    "pred.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99fbd9d8051a09a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 同样步骤进行逆变换\n",
    "original_copies_array = np.repeat(testY, 2, axis=-1)\n",
    "original = scaler.inverse_transform(np.reshape(original_copies_array, (len(testY), 2)))[:, 0]\n",
    "original.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b82ca2a7688e8b3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 对测试集输出数据进行逆变换\n",
    "prediction_copies_array = np.repeat(train_predict, 2, axis=-1)\n",
    "train_pred = scaler.inverse_transform(np.reshape(prediction_copies_array, (len(train_predict), 2)))[:, 0]\n",
    "train_pred.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef66af5058f640f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 对测试数据Y进行逆变换\n",
    "train_original_copies_array = np.repeat(trainY, 2, axis=-1)\n",
    "train_original = scaler.inverse_transform(np.reshape(train_original_copies_array, (len(trainY), 2)))[:, 0]\n",
    "train_original.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba817c2d84d88739",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "pred=pd.DataFrame(pred)\n",
    "pred.columns=['Qsim']\n",
    "pred"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cbe442ab1ba0437",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_pred=pd.DataFrame(train_pred)\n",
    "train_pred.columns=['Qsim']\n",
    "train_pred"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91811ee2478bc58c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "original=pd.DataFrame(original)\n",
    "original.columns=['Qobs']\n",
    "original"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c5917bc81c0dbf0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_original=pd.DataFrame(train_original)\n",
    "train_original.columns=['Qobs']\n",
    "train_original"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb616e0a2be2dc5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_copy=df_copy[-(test_split-30):]\n",
    "df_copy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4bbe67591550958",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "test_df=df_copy[-test_split:]\n",
    "test_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53a366e32e020f36",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_df=df_copy[n_past:-test_split]\n",
    "train_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1758dec7bee978be",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "test_df=test_df.reset_index(drop=True)\n",
    "test_df=test_df['Date']\n",
    "test_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b667dc5bc4dc3286",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_df=train_df.reset_index(drop=True)\n",
    "train_df=train_df['Date']\n",
    "train_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a73ba7e8488ea597",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "test_df_full=pd.concat([test_df,original,pred],axis=1)\n",
    "test_df_full=test_df_full.reset_index(drop=True)\n",
    "test_df_full=test_df_full.set_index('Date')\n",
    "test_df_full.to_csv('/Users/datou/PycharmProjects/model/HengyangSta/HY_data/HY_TestLSTM.csv')\n",
    "test_df_full"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b730a718c8d0bb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_df_full=pd.concat([train_df,train_original,train_pred],axis=1)\n",
    "train_df_full=train_df_full.reset_index(drop=True)\n",
    "train_df_full=train_df_full.set_index('Date')\n",
    "train_df_full.to_csv('/Users/datou/PycharmProjects/model/HengyangSta/HY_data/HY_TrainLSTM.csv')\n",
    "train_df_full"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7496d2eb7e638486",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 计算nash效率系数\n",
    "evalIndicator.eval(test_df_full[\"Qsim\"], test_df_full['Qobs'])\n",
    "# 比较预测值和原始值，进行绘图展示\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(test_df_full['Qobs'], color='red', label='Qobs')\n",
    "plt.plot(test_df_full['Qsim'], color='blue', label='Qsim',linestyle=\"--\")\n",
    "plt.title(' LSTM--')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Runoff(m3/s)')\n",
    "plt.savefig(\"/Users/datou/PycharmProjects/model/HengyangSta/HY_picture/HY_TestLSTM.png\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd7b0783dfa24cd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 计算nash效率系数\n",
    "evalIndicator.eval(train_df_full['Qsim'], train_df_full['Qobs'])\n",
    "# 比较预测值和原始值，进行绘图展示\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(train_df_full['Qobs'], color='red', label='Qobs')\n",
    "plt.plot(train_df_full['Qsim'], color='blue', label='Qsim',linestyle=\"--\")\n",
    "plt.title(' LSTM--' + 'R2: ' )\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Runoff(m3/s)')\n",
    "plt.savefig(\"/Users/datou/PycharmProjects/model/HengyangSta/HY_picture/HY_TrainLSTM.png\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83c290f970ddb2db",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# # 预测一些未来值\n",
    "# # 从主 df 数据集中获取我们在开始时加载的最后 30 个值\n",
    "# df_past = df.iloc[-30:, :]\n",
    "# # df_30_days_past.tail()\n",
    "# df_future = pd.read_csv(\"test.csv\", parse_dates=[\"Date\"], index_col=[0])\n",
    "# Qobs_future = df_future[\"Q\"]\n",
    "# # 剔除目标列\n",
    "# df_future[\"Q\"] = 0\n",
    "# df_future = df_future[[\"Q\", \"P\"]]\n",
    "# df_past = df_past.values\n",
    "# df_future"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5e2b3d9fa72d83",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# # 对数据进行缩放\n",
    "# old_scaled_array = scaler.transform(df_past)\n",
    "# new_scaled_array = scaler.transform(df_future)\n",
    "# new_scaled_df = pd.DataFrame(new_scaled_array)\n",
    "# new_scaled_df.iloc[:, 0] = np.nan\n",
    "# full_df = pd.concat([pd.DataFrame(old_scaled_array), new_scaled_df]).reset_index().drop([\"index\"], axis=1)\n",
    "# full_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "295701574c2fcc70",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 使用特征值进行预测\n",
    "# full_df_scaled_array = full_df.values\n",
    "# all_data = []\n",
    "# time_step = 30\n",
    "# for i in range(time_step, len(full_df_scaled_array)):\n",
    "#     data_x = []\n",
    "#     data_x.append(\n",
    "#         full_df_scaled_array[i - time_step:i, 0:full_df_scaled_array.shape[1]])\n",
    "#     data_x = np.array(data_x)\n",
    "#     prediction = my_model.predict(data_x)\n",
    "#     all_data.append(prediction)\n",
    "#     full_df.iloc[i, 0] = prediction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33578db55a73aac",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 对预测进行逆变换\n",
    "# new_array = np.array(all_data)\n",
    "# new_array = new_array.reshape(-1, 1)\n",
    "# prediction_copies_array = np.repeat(new_array, 2, axis=-1)\n",
    "# y_pred_future = scaler.inverse_transform(np.reshape(prediction_copies_array, (len(new_array), 2)))[:, 0]\n",
    "# y_pred_future = pd.DataFrame(y_pred_future)\n",
    "# y_pred_future"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90e736c022e360ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Qobs_future=pd.DataFrame(Qobs_future)\n",
    "# Qobs_future.reset_index(inplace=True)\n",
    "# Qobs_future"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4cb338eacf7cdd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_future_full=pd.concat([Qobs_future,y_pred_future],axis=1)\n",
    "# df_future_full.columns=['Date',\"Qobs\",\"Qsim\"]\n",
    "# df_future_full.reset_index(drop=True)\n",
    "# df_future_full=df_future_full.set_index('Date')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78e2abcb2949faba",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 绘图进行数据展示\n",
    "# nash_futrue = evalIndicator.eval(df_future_full['Qsim'], df_future_full['Qobs'])\n",
    "# plt.plot(df_future_full['Qsim'], color='green', label='Qsim')\n",
    "# plt.plot(df_future_full['Qobs'], color='yellow', label='Qobs')\n",
    "# plt.title('Verify Prediction-' + 'NSE: ' + format(nash_futrue, '.3f'))\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('Runoff(m3/s)')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6c2d16c9b9fe349",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
