{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "            Qobs         XAJ        TVGM      TANK      GR4J         BP  \\\nDate                                                                      \n1996-11-25   391  225.033998    0.000000    0.0000  735.3500  412.51212   \n1996-11-26   383  254.349212    1.243738  222.5366  677.0830  427.12274   \n1996-11-27   292  238.780517    9.174156  358.5957  500.3750  427.80844   \n1996-11-28   316  215.054604   16.085507  232.6648  393.1510  357.89010   \n1996-11-29   309  192.677854   37.273250  190.3943  322.3010  402.05334   \n...          ...         ...         ...       ...       ...        ...   \n2001-12-27   766  303.171266  201.602220  632.9010  325.1101  705.56226   \n2001-12-28   653  280.365424  164.880794  597.6152  317.9625  683.90850   \n2001-12-29   536  260.064636  138.430022  561.9181  311.1167  565.22125   \n2001-12-30   483  241.954545  119.765636  526.6976  304.5541  517.99960   \n2001-12-31   522  225.761590  106.686842  500.3691  298.2579  511.62870   \n\n                   SVR        RNN       LSTM  \nDate                                          \n1996-11-25  452.107690  330.67706  359.58588  \n1996-11-26  447.654346  335.34006  359.64227  \n1996-11-27  427.297602  334.46700  353.75110  \n1996-11-28  300.937053  258.40210  265.39352  \n1996-11-29  401.121845  293.06906  333.27728  \n...                ...        ...        ...  \n2001-12-27  796.338839  617.83813  653.80597  \n2001-12-28  816.775477  648.15950  669.88380  \n2001-12-29  622.037698  570.21160  546.56840  \n2001-12-30  532.919504  459.56644  479.90878  \n2001-12-31  515.192376  418.25632  453.35236  \n\n[1863 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Qobs</th>\n      <th>XAJ</th>\n      <th>TVGM</th>\n      <th>TANK</th>\n      <th>GR4J</th>\n      <th>BP</th>\n      <th>SVR</th>\n      <th>RNN</th>\n      <th>LSTM</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1996-11-25</th>\n      <td>391</td>\n      <td>225.033998</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>735.3500</td>\n      <td>412.51212</td>\n      <td>452.107690</td>\n      <td>330.67706</td>\n      <td>359.58588</td>\n    </tr>\n    <tr>\n      <th>1996-11-26</th>\n      <td>383</td>\n      <td>254.349212</td>\n      <td>1.243738</td>\n      <td>222.5366</td>\n      <td>677.0830</td>\n      <td>427.12274</td>\n      <td>447.654346</td>\n      <td>335.34006</td>\n      <td>359.64227</td>\n    </tr>\n    <tr>\n      <th>1996-11-27</th>\n      <td>292</td>\n      <td>238.780517</td>\n      <td>9.174156</td>\n      <td>358.5957</td>\n      <td>500.3750</td>\n      <td>427.80844</td>\n      <td>427.297602</td>\n      <td>334.46700</td>\n      <td>353.75110</td>\n    </tr>\n    <tr>\n      <th>1996-11-28</th>\n      <td>316</td>\n      <td>215.054604</td>\n      <td>16.085507</td>\n      <td>232.6648</td>\n      <td>393.1510</td>\n      <td>357.89010</td>\n      <td>300.937053</td>\n      <td>258.40210</td>\n      <td>265.39352</td>\n    </tr>\n    <tr>\n      <th>1996-11-29</th>\n      <td>309</td>\n      <td>192.677854</td>\n      <td>37.273250</td>\n      <td>190.3943</td>\n      <td>322.3010</td>\n      <td>402.05334</td>\n      <td>401.121845</td>\n      <td>293.06906</td>\n      <td>333.27728</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2001-12-27</th>\n      <td>766</td>\n      <td>303.171266</td>\n      <td>201.602220</td>\n      <td>632.9010</td>\n      <td>325.1101</td>\n      <td>705.56226</td>\n      <td>796.338839</td>\n      <td>617.83813</td>\n      <td>653.80597</td>\n    </tr>\n    <tr>\n      <th>2001-12-28</th>\n      <td>653</td>\n      <td>280.365424</td>\n      <td>164.880794</td>\n      <td>597.6152</td>\n      <td>317.9625</td>\n      <td>683.90850</td>\n      <td>816.775477</td>\n      <td>648.15950</td>\n      <td>669.88380</td>\n    </tr>\n    <tr>\n      <th>2001-12-29</th>\n      <td>536</td>\n      <td>260.064636</td>\n      <td>138.430022</td>\n      <td>561.9181</td>\n      <td>311.1167</td>\n      <td>565.22125</td>\n      <td>622.037698</td>\n      <td>570.21160</td>\n      <td>546.56840</td>\n    </tr>\n    <tr>\n      <th>2001-12-30</th>\n      <td>483</td>\n      <td>241.954545</td>\n      <td>119.765636</td>\n      <td>526.6976</td>\n      <td>304.5541</td>\n      <td>517.99960</td>\n      <td>532.919504</td>\n      <td>459.56644</td>\n      <td>479.90878</td>\n    </tr>\n    <tr>\n      <th>2001-12-31</th>\n      <td>522</td>\n      <td>225.761590</td>\n      <td>106.686842</td>\n      <td>500.3691</td>\n      <td>298.2579</td>\n      <td>511.62870</td>\n      <td>515.192376</td>\n      <td>418.25632</td>\n      <td>453.35236</td>\n    </tr>\n  </tbody>\n</table>\n<p>1863 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.read_csv(\"/Users/datou/PycharmProjects/model/HengyangSta/HY_ensemble/data/衡阳站多模型验证期结果.csv\",\n",
    "                      parse_dates=[\"Date\"])\n",
    "test_df_copy = test_df\n",
    "test_df_copy = test_df_copy.iloc[:, :2]\n",
    "test_df.reset_index(drop=True)\n",
    "test_df = test_df.set_index('Date')\n",
    "\"\"\"\n",
    "读取训练数据\n",
    "\"\"\"\n",
    "train_df = pd.read_csv(\"/Users/datou/PycharmProjects/model/HengyangSta/HY_ensemble/data/衡阳站多模型率定期结果.csv\",\n",
    "                       parse_dates=[\"Date\"])\n",
    "train_df_copy = train_df\n",
    "train_df_copy = train_df_copy.iloc[:, :2]\n",
    "train_df.reset_index(drop=True)\n",
    "train_df = train_df.set_index('Date')\n",
    "test_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T10:00:09.978449Z",
     "start_time": "2024-03-22T10:00:09.964187Z"
    }
   },
   "id": "ae4f10b7b93a7e21"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳参数组合：{'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1}\n",
      "*******************率定期*******************\n",
      "MAE:265.76307672937924\n",
      "RMSE:436.99731437687245\n",
      "NSE:0.8949155768062546\n",
      "RE:0.16581722602923338\n",
      "Qmaxe:0.054651292945906434\n",
      "Qmine:1.0742216564360119\n",
      "*******************验证期*******************\n",
      "MAE:383.05627737900164\n",
      "RMSE:640.245348932015\n",
      "NSE:0.8116167905857318\n",
      "RE:7.460804106763665\n",
      "Qmaxe:0.20938817223837208\n",
      "Qmine:1.5373973661256068\n"
     ]
    },
    {
     "data": {
      "text/plain": "(383.05627737900164,\n 640.245348932015,\n 0.8116167905857318,\n 7.460804106763665,\n 0.20938817223837208,\n 1.5373973661256068)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入进行线性回归的包\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from tool import Indicator\n",
    "\"\"\"\n",
    "案例一：XAJ+GR4J\n",
    "\"\"\"\n",
    "# 处理数据\n",
    "trainX_xaj = train_df.iloc[:, 1]\n",
    "trainX_gr4j = train_df.iloc[:, 4]\n",
    "trainy1 = train_df.iloc[:, :1]\n",
    "trainx1 = pd.merge(trainX_xaj, trainX_gr4j, on=\"Date\", how=\"left\")\n",
    "train_data1=pd.merge(trainy1,trainx1,on=\"Date\",how=\"left\")\n",
    "testX_xaj = test_df.iloc[:, 1]\n",
    "testX_gr4j = test_df.iloc[:,4]\n",
    "testy1 = test_df.iloc[:, :1]\n",
    "testx1 = pd.merge(testX_xaj, testX_gr4j, on=\"Date\", how=\"left\")\n",
    "test_data1=pd.merge(testy1,testx1,on=\"Date\",how=\"left\")\n",
    "\n",
    "# 数据归一化\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_for_training_scaled1 = scaler.fit_transform(train_data1)\n",
    "df_for_testing_scaled1 = scaler.transform(test_data1)\n",
    "\n",
    "# 划分数据\n",
    "trainX1 = df_for_training_scaled1[:, 1:]\n",
    "trainY1 = df_for_training_scaled1[:, :1]\n",
    "testX1 = df_for_testing_scaled1[:, 1:]\n",
    "testY1 = df_for_testing_scaled1[:, :1]\n",
    "\n",
    "\n",
    "# XGBoost\n",
    "parameters = {\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.15, 0.025],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample':[ 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "xlf = xgb.XGBRegressor()\n",
    "grid_search = GridSearchCV(xlf, param_grid=parameters, cv=5)\n",
    "grid_search = grid_search.fit(trainX1, trainY1)\n",
    "# 拟合数据集\n",
    "model1 = grid_search.best_estimator_\n",
    "print(\"最佳参数组合：\"+str(grid_search.best_params_))\n",
    "\n",
    "train_predict1 = model1.predict(trainX1)\n",
    "train_predict1 = pd.DataFrame(train_predict1)\n",
    "train_predict1.columns = [\"XGBoost1\"]\n",
    "\n",
    "test_predict1 = model1.predict(testX1)\n",
    "test_predict1 = pd.DataFrame(test_predict1)\n",
    "test_predict1.columns = [\"XGBoost1\"]\n",
    "\n",
    "\n",
    "# 逆缩放过程\n",
    "# 改变形状来进行逆缩放，逆变换后的第一列是我们需要的，所以我们在最后使用了 → [:,0]。\n",
    "y_pred_copy = np.repeat(test_predict1,len(test_data1.columns), axis=-1)\n",
    "test_pred1 = scaler.inverse_transform(np.reshape(y_pred_copy, (len(test_predict1),len(test_data1.columns))))[:, 0]\n",
    "test_pred_copy1 = test_pred1\n",
    "test_pred1 = pd.DataFrame(test_pred1)\n",
    "test_pred1.columns = [\"XGBoost1\"]\n",
    "\n",
    "prediction_copies_array = np.repeat(train_predict1,len(test_data1.columns), axis=-1)\n",
    "train_pred1 = scaler.inverse_transform(np.reshape(prediction_copies_array, (len(train_predict1),len(test_data1.columns))))[:, 0]\n",
    "train_pred_copy1 = train_pred1\n",
    "train_pred1=pd.DataFrame(train_pred1)\n",
    "train_pred1.columns=['XGBoost1']\n",
    "\n",
    "\n",
    "# 计算nash效率系数\n",
    "print(\"*******************率定期*******************\")\n",
    "Indicator.eval(train_pred1['XGBoost1'], train_df_copy['Qobs'])\n",
    "print(\"*******************验证期*******************\")\n",
    "Indicator.eval(test_pred1['XGBoost1'], test_df_copy['Qobs'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T10:01:14.018260Z",
     "start_time": "2024-03-22T10:00:13.615723Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳参数组合：{'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1}\n",
      "*******************率定期*******************\n",
      "MAE:125.72220531068149\n",
      "RMSE:240.17724357539535\n",
      "NSE:0.9682572519972895\n",
      "RE:0.15871996982967906\n",
      "Qmaxe:0.02390670687134503\n",
      "Qmine:0.5561751108320933\n",
      "*******************验证期*******************\n",
      "MAE:178.62639074484252\n",
      "RMSE:348.4104212489616\n",
      "NSE:0.9442131807399858\n",
      "RE:0.12397681675968615\n",
      "Qmaxe:0.208197144500969\n",
      "Qmine:0.9036705239305218\n"
     ]
    },
    {
     "data": {
      "text/plain": "(178.62639074484252,\n 348.4104212489616,\n 0.9442131807399858,\n 0.12397681675968615,\n 0.208197144500969,\n 0.9036705239305218)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "案例二：LSTM+RNN\n",
    "\"\"\"\n",
    "# 处理数据\n",
    "trainX_LSTM = train_df.iloc[:, 7]\n",
    "trainX_RNN = train_df.iloc[:, 8]\n",
    "trainy2 = train_df.iloc[:, :1]\n",
    "trainx2 = pd.merge(trainX_LSTM, trainX_RNN, on=\"Date\", how=\"left\")\n",
    "testX_LSTM = test_df.iloc[:, 7]\n",
    "testX_RNN = test_df.iloc[:, 8]\n",
    "testy2 = test_df.iloc[:, :1]\n",
    "testx2 = pd.merge(testX_LSTM, testX_RNN, on=\"Date\", how=\"left\")\n",
    "train_data2=pd.merge(trainy2,trainx2,on=\"Date\",how=\"left\")\n",
    "test_data2=pd.merge(testy2,testx2,on=\"Date\",how=\"left\")\n",
    "\n",
    "# 数据归一化\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_for_training_scaled2 = scaler.fit_transform(train_data2)\n",
    "df_for_testing_scaled2 = scaler.transform(test_data2)\n",
    "\n",
    "# 划分数据\n",
    "trainX2 = df_for_training_scaled2[:, 1:]\n",
    "trainY2 = df_for_training_scaled2[:, :1]\n",
    "testX2 = df_for_testing_scaled2[:, 1:]\n",
    "testY2 = df_for_testing_scaled2[:, :1]\n",
    "\n",
    "\n",
    "# 随机森林回归器\n",
    "parameters = {\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.15, 0.025],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample':[ 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "xlf = xgb.XGBRegressor()\n",
    "grid_search = GridSearchCV(xlf, param_grid=parameters, cv=5)\n",
    "grid_search = grid_search.fit(trainX2, trainY2)\n",
    "# 拟合数据集\n",
    "model1 = grid_search.best_estimator_\n",
    "print(\"最佳参数组合：\"+str(grid_search.best_params_))\n",
    "\n",
    "train_predict2 = model1.predict(trainX2)\n",
    "train_predict2 = pd.DataFrame(train_predict2)\n",
    "train_predict2.columns = [\"XGBoost2\"]\n",
    "\n",
    "test_predict2 = model1.predict(testX2)\n",
    "test_predict2 = pd.DataFrame(test_predict2)\n",
    "test_predict2.columns = [\"XGBoost2\"]\n",
    "\n",
    "\n",
    "# 逆缩放过程\n",
    "# 改变形状来进行逆缩放，逆变换后的第一列是我们需要的，所以我们在最后使用了 → [:,0]。\n",
    "y_pred_copy = np.repeat(test_predict2,len(test_data2.columns), axis=-1)\n",
    "test_pred2 = scaler.inverse_transform(np.reshape(y_pred_copy, (len(test_predict2),len(test_data2.columns))))[:, 0]\n",
    "test_pred_copy2 = test_pred2\n",
    "test_pred2 = pd.DataFrame(test_pred2)\n",
    "test_pred2.columns = [\"XGBoost2\"]\n",
    "\n",
    "prediction_copies_array = np.repeat(train_predict2,len(test_data2.columns), axis=-1)\n",
    "train_pred2 = scaler.inverse_transform(np.reshape(prediction_copies_array, (len(train_predict2),len(test_data2.columns))))[:, 0]\n",
    "train_pred_copy2 = train_pred2\n",
    "train_pred2=pd.DataFrame(train_pred2)\n",
    "train_pred2.columns=['XGBoost2']\n",
    "\n",
    "\n",
    "# 计算nash效率系数\n",
    "print(\"*******************率定期*******************\")\n",
    "Indicator.eval(train_pred2['XGBoost2'], train_df_copy['Qobs'])\n",
    "print(\"*******************验证期*******************\")\n",
    "Indicator.eval(test_pred2['XGBoost2'], test_df_copy['Qobs'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T10:02:10.495281Z",
     "start_time": "2024-03-22T10:01:23.137002Z"
    }
   },
   "id": "4aa691d9a8d986df"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳参数组合：{'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1}\n",
      "*******************率定期*******************\n",
      "MAE:122.06047954044064\n",
      "RMSE:224.81337122031127\n",
      "NSE:0.9721884569517975\n",
      "RE:0.16339882343047413\n",
      "Qmaxe:0.03582156889619883\n",
      "Qmine:0.6594978211418031\n",
      "*******************验证期*******************\n",
      "MAE:180.03341082635902\n",
      "RMSE:347.3245215842442\n",
      "NSE:0.9445603832388575\n",
      "RE:1.0165826388028458\n",
      "Qmaxe:0.20870208030523255\n",
      "Qmine:1.0300652957657008\n"
     ]
    },
    {
     "data": {
      "text/plain": "(180.03341082635902,\n 347.3245215842442,\n 0.9445603832388575,\n 1.0165826388028458,\n 0.20870208030523255,\n 1.0300652957657008)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "案例三：BP+RNN+XAJ+TANK\n",
    "\"\"\"\n",
    "# 处理数据\n",
    "# 处理数据\n",
    "trainy3 = train_df.iloc[:, :1]\n",
    "trainx3 = pd.merge(trainx1, trainx2, on=\"Date\", how=\"left\")\n",
    "testy3 = test_df.iloc[:, :1]\n",
    "testx3 = pd.merge(testx1, testx2, on=\"Date\", how=\"left\")\n",
    "train_data3=pd.merge(trainy3,trainx3,on=\"Date\",how=\"left\")\n",
    "test_data3=pd.merge(testy3,testx3,on=\"Date\",how=\"left\")\n",
    "\n",
    "# 数据归一化\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_for_training_scaled3 = scaler.fit_transform(train_data3)\n",
    "df_for_testing_scaled3 = scaler.transform(test_data3)\n",
    "\n",
    "# 划分数据\n",
    "trainX3 = df_for_training_scaled3[:, 1:]\n",
    "trainY3 = df_for_training_scaled3[:, :1]\n",
    "testX3 = df_for_testing_scaled3[:, 1:]\n",
    "testY3 = df_for_testing_scaled3[:, :1]\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.15, 0.025],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample':[ 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "xlf = xgb.XGBRegressor()\n",
    "grid_search = GridSearchCV(xlf, param_grid=parameters, cv=5)\n",
    "grid_search = grid_search.fit(trainX3, trainY3)\n",
    "# 拟合数据集\n",
    "model1 = grid_search.best_estimator_\n",
    "print(\"最佳参数组合：\"+str(grid_search.best_params_))\n",
    "\n",
    "train_predict3 = model1.predict(trainX3)\n",
    "train_predict3 = pd.DataFrame(train_predict3)\n",
    "train_predict3.columns = [\"XGBoost3\"]\n",
    "\n",
    "test_predict3 = model1.predict(testX3)\n",
    "test_predict3 = pd.DataFrame(test_predict3)\n",
    "test_predict3.columns = [\"XGBoost3\"]\n",
    "\n",
    "\n",
    "# 逆缩放过程\n",
    "# 改变形状来进行逆缩放，逆变换后的第一列是我们需要的，所以我们在最后使用了 → [:,0]。\n",
    "y_pred_copy = np.repeat(test_predict3,len(test_data3.columns), axis=-1)\n",
    "test_pred3= scaler.inverse_transform(np.reshape(y_pred_copy, (len(test_predict3),len(test_data3.columns))))[:, 0]\n",
    "test_pred_copy3 = test_pred3\n",
    "test_pred3 = pd.DataFrame(test_pred3)\n",
    "test_pred3.columns = [\"XGBoost3\"]\n",
    "\n",
    "prediction_copies_array = np.repeat(train_predict3,len(test_data3.columns), axis=-1)\n",
    "train_pred3 = scaler.inverse_transform(np.reshape(prediction_copies_array, (len(train_predict3),len(test_data3.columns))))[:, 0]\n",
    "train_pred_copy3 = train_pred3\n",
    "train_pred3=pd.DataFrame(train_pred3)\n",
    "train_pred3.columns=['XGBoost3']\n",
    "\n",
    "\n",
    "# 计算nash效率系数\n",
    "print(\"*******************率定期*******************\")\n",
    "Indicator.eval(train_pred3['XGBoost3'], train_df_copy['Qobs'])\n",
    "print(\"*******************验证期*******************\")\n",
    "Indicator.eval(test_pred3['XGBoost3'], test_df_copy['Qobs'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T10:03:31.437877Z",
     "start_time": "2024-03-22T10:02:18.013127Z"
    }
   },
   "id": "9ee3fa8999146837"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "            Qobs    XGBoost1    XGBoost2    XGBoost3\nDate                                                \n1985-01-16   479  788.259949  482.629578  511.886963\n1985-01-17   542  788.259949  440.507172  474.851776\n1985-01-18   557  788.259949  587.034485  619.759521\n1985-01-19   476  771.178040  530.957886  563.682922\n1985-01-20   464  714.305542  440.507172  472.252289\n...          ...         ...         ...         ...\n1996-11-20   374  339.411713  369.569916  371.115326\n1996-11-21   315  339.411713  369.569916  371.115326\n1996-11-22   300  339.411713  311.918915  316.701782\n1996-11-23   336  339.411713  311.918915  316.701782\n1996-11-24   378  339.411713  344.178558  345.723938\n\n[4331 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Qobs</th>\n      <th>XGBoost1</th>\n      <th>XGBoost2</th>\n      <th>XGBoost3</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1985-01-16</th>\n      <td>479</td>\n      <td>788.259949</td>\n      <td>482.629578</td>\n      <td>511.886963</td>\n    </tr>\n    <tr>\n      <th>1985-01-17</th>\n      <td>542</td>\n      <td>788.259949</td>\n      <td>440.507172</td>\n      <td>474.851776</td>\n    </tr>\n    <tr>\n      <th>1985-01-18</th>\n      <td>557</td>\n      <td>788.259949</td>\n      <td>587.034485</td>\n      <td>619.759521</td>\n    </tr>\n    <tr>\n      <th>1985-01-19</th>\n      <td>476</td>\n      <td>771.178040</td>\n      <td>530.957886</td>\n      <td>563.682922</td>\n    </tr>\n    <tr>\n      <th>1985-01-20</th>\n      <td>464</td>\n      <td>714.305542</td>\n      <td>440.507172</td>\n      <td>472.252289</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1996-11-20</th>\n      <td>374</td>\n      <td>339.411713</td>\n      <td>369.569916</td>\n      <td>371.115326</td>\n    </tr>\n    <tr>\n      <th>1996-11-21</th>\n      <td>315</td>\n      <td>339.411713</td>\n      <td>369.569916</td>\n      <td>371.115326</td>\n    </tr>\n    <tr>\n      <th>1996-11-22</th>\n      <td>300</td>\n      <td>339.411713</td>\n      <td>311.918915</td>\n      <td>316.701782</td>\n    </tr>\n    <tr>\n      <th>1996-11-23</th>\n      <td>336</td>\n      <td>339.411713</td>\n      <td>311.918915</td>\n      <td>316.701782</td>\n    </tr>\n    <tr>\n      <th>1996-11-24</th>\n      <td>378</td>\n      <td>339.411713</td>\n      <td>344.178558</td>\n      <td>345.723938</td>\n    </tr>\n  </tbody>\n</table>\n<p>4331 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_full = pd.concat([test_df_copy, test_pred1, test_pred2, test_pred3], axis=1)\n",
    "test_df_full = test_df_full.reset_index(drop=True)\n",
    "test_df_full = test_df_full.set_index('Date')\n",
    "test_df_full.to_csv(\"/Users/datou/PycharmProjects/model/HengyangSta/HY_ensemble/data/HY_XGBoost1Test.csv\")\n",
    "train_df_full = pd.concat([train_df_copy, train_pred1, train_pred2, train_pred3], axis=1)\n",
    "train_df_full = train_df_full.reset_index(drop=True)\n",
    "train_df_full = train_df_full.set_index('Date')\n",
    "train_df_full.to_csv(\"/Users/datou/PycharmProjects/model/HengyangSta/HY_ensemble/data/HY_XGBoost1Train.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T10:04:25.829037Z",
     "start_time": "2024-03-22T10:04:25.810747Z"
    }
   },
   "id": "c0ec365ed0ce39c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
