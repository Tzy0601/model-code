{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "                  Qobs         XAJ        TVGM       TANK        GR4J  \\\nDate                                                                    \n2000-03-19  146.646083  113.312715   52.709690  180.82450  161.918257   \n2000-03-20  126.275542   77.366574   45.722771  132.35930  151.888716   \n2000-03-21  116.957458   67.217913   43.718240  109.94270  120.206044   \n2000-03-22  107.373583   69.118466   43.801287   97.71193  107.209378   \n2000-03-23  157.025792  112.531645   62.675173  156.76230  128.057335   \n...                ...         ...         ...        ...         ...   \n2013-03-22  179.575000  202.368997  133.070349  224.24750  301.949810   \n2013-03-23  254.883333  188.156255  102.059662  170.45160  188.006705   \n2013-03-24  518.239583  253.698090  126.938355  199.69960  207.666900   \n2013-03-25  342.933333  446.655621  248.432716  466.61090  434.059795   \n2013-03-26  363.845833  295.128525  170.958371  266.59370  383.208458   \n\n                    BP         SVR       LSTM        RNN  \nDate                                                      \n2000-03-19  225.542370  151.506776  210.58240  203.54922  \n2000-03-20  122.160250  149.861280  140.79071  100.39914  \n2000-03-21   92.493935  132.048647  131.23845  104.74185  \n2000-03-22  101.336530  131.638650  116.44574  101.35420  \n2000-03-23  209.905500  122.400853  198.44711  141.74525  \n...                ...         ...        ...        ...  \n2013-03-22  167.668520  214.686714  177.10118  144.76294  \n2013-03-23  113.537680  152.147893  139.23248  154.90280  \n2013-03-24  218.423450  224.147323  215.14694  187.25436  \n2013-03-25  470.192720  384.483474  495.62650  390.83618  \n2013-03-26  209.236130  250.547044  233.61449  260.68106  \n\n[4756 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Qobs</th>\n      <th>XAJ</th>\n      <th>TVGM</th>\n      <th>TANK</th>\n      <th>GR4J</th>\n      <th>BP</th>\n      <th>SVR</th>\n      <th>LSTM</th>\n      <th>RNN</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2000-03-19</th>\n      <td>146.646083</td>\n      <td>113.312715</td>\n      <td>52.709690</td>\n      <td>180.82450</td>\n      <td>161.918257</td>\n      <td>225.542370</td>\n      <td>151.506776</td>\n      <td>210.58240</td>\n      <td>203.54922</td>\n    </tr>\n    <tr>\n      <th>2000-03-20</th>\n      <td>126.275542</td>\n      <td>77.366574</td>\n      <td>45.722771</td>\n      <td>132.35930</td>\n      <td>151.888716</td>\n      <td>122.160250</td>\n      <td>149.861280</td>\n      <td>140.79071</td>\n      <td>100.39914</td>\n    </tr>\n    <tr>\n      <th>2000-03-21</th>\n      <td>116.957458</td>\n      <td>67.217913</td>\n      <td>43.718240</td>\n      <td>109.94270</td>\n      <td>120.206044</td>\n      <td>92.493935</td>\n      <td>132.048647</td>\n      <td>131.23845</td>\n      <td>104.74185</td>\n    </tr>\n    <tr>\n      <th>2000-03-22</th>\n      <td>107.373583</td>\n      <td>69.118466</td>\n      <td>43.801287</td>\n      <td>97.71193</td>\n      <td>107.209378</td>\n      <td>101.336530</td>\n      <td>131.638650</td>\n      <td>116.44574</td>\n      <td>101.35420</td>\n    </tr>\n    <tr>\n      <th>2000-03-23</th>\n      <td>157.025792</td>\n      <td>112.531645</td>\n      <td>62.675173</td>\n      <td>156.76230</td>\n      <td>128.057335</td>\n      <td>209.905500</td>\n      <td>122.400853</td>\n      <td>198.44711</td>\n      <td>141.74525</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2013-03-22</th>\n      <td>179.575000</td>\n      <td>202.368997</td>\n      <td>133.070349</td>\n      <td>224.24750</td>\n      <td>301.949810</td>\n      <td>167.668520</td>\n      <td>214.686714</td>\n      <td>177.10118</td>\n      <td>144.76294</td>\n    </tr>\n    <tr>\n      <th>2013-03-23</th>\n      <td>254.883333</td>\n      <td>188.156255</td>\n      <td>102.059662</td>\n      <td>170.45160</td>\n      <td>188.006705</td>\n      <td>113.537680</td>\n      <td>152.147893</td>\n      <td>139.23248</td>\n      <td>154.90280</td>\n    </tr>\n    <tr>\n      <th>2013-03-24</th>\n      <td>518.239583</td>\n      <td>253.698090</td>\n      <td>126.938355</td>\n      <td>199.69960</td>\n      <td>207.666900</td>\n      <td>218.423450</td>\n      <td>224.147323</td>\n      <td>215.14694</td>\n      <td>187.25436</td>\n    </tr>\n    <tr>\n      <th>2013-03-25</th>\n      <td>342.933333</td>\n      <td>446.655621</td>\n      <td>248.432716</td>\n      <td>466.61090</td>\n      <td>434.059795</td>\n      <td>470.192720</td>\n      <td>384.483474</td>\n      <td>495.62650</td>\n      <td>390.83618</td>\n    </tr>\n    <tr>\n      <th>2013-03-26</th>\n      <td>363.845833</td>\n      <td>295.128525</td>\n      <td>170.958371</td>\n      <td>266.59370</td>\n      <td>383.208458</td>\n      <td>209.236130</td>\n      <td>250.547044</td>\n      <td>233.61449</td>\n      <td>260.68106</td>\n    </tr>\n  </tbody>\n</table>\n<p>4756 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.read_csv(\"/Users/datou/PycharmProjects/model/JianyangSta/JY_ensemble/data/建阳站多模型验证期结果.csv\",\n",
    "                      parse_dates=[\"Date\"])\n",
    "test_df_copy = test_df\n",
    "test_df_copy = test_df_copy.iloc[:, :2]\n",
    "test_df.reset_index(drop=True)\n",
    "test_df = test_df.set_index('Date')\n",
    "\"\"\"\n",
    "读取训练数据\n",
    "\"\"\"\n",
    "train_df = pd.read_csv(\"/Users/datou/PycharmProjects/model/JianyangSta/JY_ensemble/data/建阳站多模型率定期结果.csv\",\n",
    "                       parse_dates=[\"Date\"])\n",
    "train_df_copy = train_df\n",
    "train_df_copy = train_df_copy.iloc[:, :2]\n",
    "train_df.reset_index(drop=True)\n",
    "train_df = train_df.set_index('Date')\n",
    "train_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T10:12:30.156031Z",
     "start_time": "2024-03-22T10:12:29.921075Z"
    }
   },
   "id": "ae4f10b7b93a7e21"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳参数组合：{'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.9}\n",
      "*******************率定期*******************\n",
      "MAE:42.73587338478338\n",
      "RMSE:93.52885662485674\n",
      "NSE:0.8710184556649678\n",
      "RE:0.4108867890664687\n",
      "Qmaxe:0.04376465604511071\n",
      "Qmine:3.434900906929874\n",
      "*******************验证期*******************\n",
      "MAE:57.72064639423327\n",
      "RMSE:141.67421753104497\n",
      "NSE:0.7502022157694171\n",
      "RE:-8.062691639604667\n",
      "Qmaxe:0.23647912400305168\n",
      "Qmine:0.9654709808959321\n"
     ]
    },
    {
     "data": {
      "text/plain": "(57.72064639423327,\n 141.67421753104497,\n 0.7502022157694171,\n -8.062691639604667,\n 0.23647912400305168,\n 0.9654709808959321)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入进行线性回归的包\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from tool import Indicator\n",
    "\"\"\"\n",
    "案例一：XAJ+TANK\n",
    "\"\"\"\n",
    "# 处理数据\n",
    "trainX_xaj = train_df.iloc[:, 1]\n",
    "trainX_tank = train_df.iloc[:, 3]\n",
    "trainy1 = train_df.iloc[:, :1]\n",
    "trainx1 = pd.merge(trainX_xaj, trainX_tank, on=\"Date\", how=\"left\")\n",
    "train_data1=pd.merge(trainy1,trainx1,on=\"Date\",how=\"left\")\n",
    "testX_xaj = test_df.iloc[:, 1]\n",
    "testX_tank = test_df.iloc[:, 3]\n",
    "testy1 = test_df.iloc[:, :1]\n",
    "testx1 = pd.merge(testX_xaj, testX_tank, on=\"Date\", how=\"left\")\n",
    "test_data1=pd.merge(testy1,testx1,on=\"Date\",how=\"left\")\n",
    "\n",
    "# 数据归一化\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_for_training_scaled1 = scaler.fit_transform(train_data1)\n",
    "df_for_testing_scaled1 = scaler.transform(test_data1)\n",
    "\n",
    "# 划分数据\n",
    "trainX1 = df_for_training_scaled1[:, 1:]\n",
    "trainY1 = df_for_training_scaled1[:, :1]\n",
    "testX1 = df_for_testing_scaled1[:, 1:]\n",
    "testY1 = df_for_testing_scaled1[:, :1]\n",
    "\n",
    "\n",
    "# XGBoost\n",
    "parameters = {\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.15, 0.025],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample':[ 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "xlf = xgb.XGBRegressor()\n",
    "grid_search = GridSearchCV(xlf, param_grid=parameters, cv=5)\n",
    "grid_search = grid_search.fit(trainX1, trainY1)\n",
    "# 拟合数据集\n",
    "model1 = grid_search.best_estimator_\n",
    "print(\"最佳参数组合：\"+str(grid_search.best_params_))\n",
    "\n",
    "train_predict1 = model1.predict(trainX1)\n",
    "train_predict1 = pd.DataFrame(train_predict1)\n",
    "train_predict1.columns = [\"RF1\"]\n",
    "\n",
    "test_predict1 = model1.predict(testX1)\n",
    "test_predict1 = pd.DataFrame(test_predict1)\n",
    "test_predict1.columns = [\"RF1\"]\n",
    "\n",
    "\n",
    "# 逆缩放过程\n",
    "# 改变形状来进行逆缩放，逆变换后的第一列是我们需要的，所以我们在最后使用了 → [:,0]。\n",
    "y_pred_copy = np.repeat(test_predict1,len(test_data1.columns), axis=-1)\n",
    "test_pred1 = scaler.inverse_transform(np.reshape(y_pred_copy, (len(test_predict1),len(test_data1.columns))))[:, 0]\n",
    "test_pred_copy1 = test_pred1\n",
    "test_pred1 = pd.DataFrame(test_pred1)\n",
    "test_pred1.columns = [\"XGBoost1\"]\n",
    "\n",
    "prediction_copies_array = np.repeat(train_predict1,len(test_data1.columns), axis=-1)\n",
    "train_pred1 = scaler.inverse_transform(np.reshape(prediction_copies_array, (len(train_predict1),len(test_data1.columns))))[:, 0]\n",
    "train_pred_copy1 = train_pred1\n",
    "train_pred1=pd.DataFrame(train_pred1)\n",
    "train_pred1.columns=['XGBoost1']\n",
    "\n",
    "\n",
    "# 计算nash效率系数\n",
    "print(\"*******************率定期*******************\")\n",
    "Indicator.eval(train_pred1['XGBoost1'], train_df_copy['Qobs'])\n",
    "print(\"*******************验证期*******************\")\n",
    "Indicator.eval(test_pred1['XGBoost1'], test_df_copy['Qobs'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T10:13:17.378750Z",
     "start_time": "2024-03-22T10:12:30.195521Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳参数组合：{'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1}\n",
      "*******************率定期*******************\n",
      "MAE:36.47000211443946\n",
      "RMSE:89.70903801449288\n",
      "NSE:0.8813388039930139\n",
      "RE:0.4568810023353179\n",
      "Qmaxe:0.030088491960179042\n",
      "Qmine:2.1148497183339776\n",
      "*******************验证期*******************\n",
      "MAE:52.51972212042175\n",
      "RMSE:143.08302989226837\n",
      "NSE:0.745209522608854\n",
      "RE:-5.075403555516015\n",
      "Qmaxe:0.3455799335317012\n",
      "Qmine:0.6159285456098844\n"
     ]
    },
    {
     "data": {
      "text/plain": "(52.51972212042175,\n 143.08302989226837,\n 0.745209522608854,\n -5.075403555516015,\n 0.3455799335317012,\n 0.6159285456098844)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "案例二：BP+RNN\n",
    "\"\"\"\n",
    "# 处理数据\n",
    "trainX_BP = train_df.iloc[:, 5]\n",
    "trainX_RNN = train_df.iloc[:, 7]\n",
    "trainy2 = train_df.iloc[:, :1]\n",
    "trainx2 = pd.merge(trainX_BP, trainX_RNN, on=\"Date\", how=\"left\")\n",
    "testX_BP = test_df.iloc[:, 5]\n",
    "testX_RNN = test_df.iloc[:, 7]\n",
    "testy2 = test_df.iloc[:, :1]\n",
    "testx2 = pd.merge(testX_BP, testX_RNN, on=\"Date\", how=\"left\")\n",
    "train_data2=pd.merge(trainy2,trainx2,on=\"Date\",how=\"left\")\n",
    "test_data2=pd.merge(testy2,testx2,on=\"Date\",how=\"left\")\n",
    "\n",
    "# 数据归一化\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_for_training_scaled2 = scaler.fit_transform(train_data2)\n",
    "df_for_testing_scaled2 = scaler.transform(test_data2)\n",
    "\n",
    "# 划分数据\n",
    "trainX2 = df_for_training_scaled2[:, 1:]\n",
    "trainY2 = df_for_training_scaled2[:, :1]\n",
    "testX2 = df_for_testing_scaled2[:, 1:]\n",
    "testY2 = df_for_testing_scaled2[:, :1]\n",
    "\n",
    "\n",
    "# 随机森林回归器\n",
    "parameters = {\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.15, 0.025],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample':[ 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "xlf = xgb.XGBRegressor()\n",
    "grid_search = GridSearchCV(xlf, param_grid=parameters, cv=5)\n",
    "grid_search = grid_search.fit(trainX2, trainY2)\n",
    "# 拟合数据集\n",
    "model1 = grid_search.best_estimator_\n",
    "print(\"最佳参数组合：\"+str(grid_search.best_params_))\n",
    "\n",
    "train_predict2 = model1.predict(trainX2)\n",
    "train_predict2 = pd.DataFrame(train_predict2)\n",
    "train_predict2.columns = [\"XGBoost2\"]\n",
    "\n",
    "test_predict2 = model1.predict(testX2)\n",
    "test_predict2 = pd.DataFrame(test_predict2)\n",
    "test_predict2.columns = [\"XGBoost2\"]\n",
    "\n",
    "\n",
    "# 逆缩放过程\n",
    "# 改变形状来进行逆缩放，逆变换后的第一列是我们需要的，所以我们在最后使用了 → [:,0]。\n",
    "y_pred_copy = np.repeat(test_predict2,len(test_data2.columns), axis=-1)\n",
    "test_pred2 = scaler.inverse_transform(np.reshape(y_pred_copy, (len(test_predict2),len(test_data2.columns))))[:, 0]\n",
    "test_pred_copy2 = test_pred2\n",
    "test_pred2 = pd.DataFrame(test_pred2)\n",
    "test_pred2.columns = [\"XGBoost2\"]\n",
    "\n",
    "prediction_copies_array = np.repeat(train_predict2,len(test_data2.columns), axis=-1)\n",
    "train_pred2 = scaler.inverse_transform(np.reshape(prediction_copies_array, (len(train_predict2),len(test_data2.columns))))[:, 0]\n",
    "train_pred_copy2 = train_pred2\n",
    "train_pred2=pd.DataFrame(train_pred2)\n",
    "train_pred2.columns=['XGBoost2']\n",
    "\n",
    "\n",
    "# 计算nash效率系数\n",
    "print(\"*******************率定期*******************\")\n",
    "Indicator.eval(train_pred2['XGBoost2'], train_df_copy['Qobs'])\n",
    "print(\"*******************验证期*******************\")\n",
    "Indicator.eval(test_pred2['XGBoost2'], test_df_copy['Qobs'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T10:14:03.117565Z",
     "start_time": "2024-03-22T10:13:17.374537Z"
    }
   },
   "id": "4aa691d9a8d986df"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳参数组合：{'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1}\n",
      "*******************率定期*******************\n",
      "MAE:35.113922032552615\n",
      "RMSE:84.27226380540753\n",
      "NSE:0.8952857845448523\n",
      "RE:0.4582018737355483\n",
      "Qmaxe:0.034179205609345786\n",
      "Qmine:2.37471930189816\n",
      "*******************验证期*******************\n",
      "MAE:51.98776274853689\n",
      "RMSE:140.66234207747144\n",
      "NSE:0.7537577193100944\n",
      "RE:-5.114857624310182\n",
      "Qmaxe:0.32174781469973057\n",
      "Qmine:0.7076961224512849\n"
     ]
    },
    {
     "data": {
      "text/plain": "(51.98776274853689,\n 140.66234207747144,\n 0.7537577193100944,\n -5.114857624310182,\n 0.32174781469973057,\n 0.7076961224512849)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "案例三：BP+RNN+XAJ+TANK\n",
    "\"\"\"\n",
    "# 处理数据\n",
    "# 处理数据\n",
    "trainy3 = train_df.iloc[:, :1]\n",
    "trainx3 = pd.merge(trainx1, trainx2, on=\"Date\", how=\"left\")\n",
    "testy3 = test_df.iloc[:, :1]\n",
    "testx3 = pd.merge(testx1, testx2, on=\"Date\", how=\"left\")\n",
    "train_data3=pd.merge(trainy3,trainx3,on=\"Date\",how=\"left\")\n",
    "test_data3=pd.merge(testy3,testx3,on=\"Date\",how=\"left\")\n",
    "\n",
    "# 数据归一化\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_for_training_scaled3 = scaler.fit_transform(train_data3)\n",
    "df_for_testing_scaled3 = scaler.transform(test_data3)\n",
    "\n",
    "# 划分数据\n",
    "trainX3 = df_for_training_scaled3[:, 1:]\n",
    "trainY3 = df_for_training_scaled3[:, :1]\n",
    "testX3 = df_for_testing_scaled3[:, 1:]\n",
    "testY3 = df_for_testing_scaled3[:, :1]\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.15, 0.025],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample':[ 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "xlf = xgb.XGBRegressor()\n",
    "grid_search = GridSearchCV(xlf, param_grid=parameters, cv=5)\n",
    "grid_search = grid_search.fit(trainX3, trainY3)\n",
    "# 拟合数据集\n",
    "model1 = grid_search.best_estimator_\n",
    "print(\"最佳参数组合：\"+str(grid_search.best_params_))\n",
    "\n",
    "train_predict3 = model1.predict(trainX3)\n",
    "train_predict3 = pd.DataFrame(train_predict3)\n",
    "train_predict3.columns = [\"XGBoost3\"]\n",
    "\n",
    "test_predict3 = model1.predict(testX3)\n",
    "test_predict3 = pd.DataFrame(test_predict3)\n",
    "test_predict3.columns = [\"XGBoost3\"]\n",
    "\n",
    "\n",
    "# 逆缩放过程\n",
    "# 改变形状来进行逆缩放，逆变换后的第一列是我们需要的，所以我们在最后使用了 → [:,0]。\n",
    "y_pred_copy = np.repeat(test_predict3,len(test_data3.columns), axis=-1)\n",
    "test_pred3= scaler.inverse_transform(np.reshape(y_pred_copy, (len(test_predict3),len(test_data3.columns))))[:, 0]\n",
    "test_pred_copy3 = test_pred3\n",
    "test_pred3 = pd.DataFrame(test_pred3)\n",
    "test_pred3.columns = [\"XGBoost3\"]\n",
    "\n",
    "prediction_copies_array = np.repeat(train_predict3,len(test_data3.columns), axis=-1)\n",
    "train_pred3 = scaler.inverse_transform(np.reshape(prediction_copies_array, (len(train_predict3),len(test_data3.columns))))[:, 0]\n",
    "train_pred_copy3 = train_pred3\n",
    "train_pred3=pd.DataFrame(train_pred3)\n",
    "train_pred3.columns=['XGBoost3']\n",
    "\n",
    "\n",
    "# 计算nash效率系数\n",
    "print(\"*******************率定期*******************\")\n",
    "Indicator.eval(train_pred3['XGBoost3'], train_df_copy['Qobs'])\n",
    "print(\"*******************验证期*******************\")\n",
    "Indicator.eval(test_pred3['XGBoost3'], test_df_copy['Qobs'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T10:15:05.234990Z",
     "start_time": "2024-03-22T10:14:03.121741Z"
    }
   },
   "id": "9ee3fa8999146837"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                  Qobs   XGBoost1    XGBoost2    XGBoost3\nDate                                                     \n2013-03-27  357.285417  46.729073  555.195129  530.587280\n2013-03-28  266.375000  46.729073  248.987610  197.105453\n2013-03-29  292.975000  46.729073  248.987610  197.105453\n2013-03-30  279.295833  83.401169  331.893494  281.143646\n2013-03-31  263.750000  80.001541  242.123825  183.926468\n...                ...        ...         ...         ...\n2018-10-26   39.116250  62.064590   51.340519   53.530777\n2018-10-27   46.711250  99.087975  102.818413   99.458435\n2018-10-28   70.970417  89.584068  102.818413   94.906242\n2018-10-29   64.495417  83.401169   92.461655   91.614349\n2018-10-30   59.041250  65.464226   65.841728   65.735146\n\n[2044 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Qobs</th>\n      <th>XGBoost1</th>\n      <th>XGBoost2</th>\n      <th>XGBoost3</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2013-03-27</th>\n      <td>357.285417</td>\n      <td>46.729073</td>\n      <td>555.195129</td>\n      <td>530.587280</td>\n    </tr>\n    <tr>\n      <th>2013-03-28</th>\n      <td>266.375000</td>\n      <td>46.729073</td>\n      <td>248.987610</td>\n      <td>197.105453</td>\n    </tr>\n    <tr>\n      <th>2013-03-29</th>\n      <td>292.975000</td>\n      <td>46.729073</td>\n      <td>248.987610</td>\n      <td>197.105453</td>\n    </tr>\n    <tr>\n      <th>2013-03-30</th>\n      <td>279.295833</td>\n      <td>83.401169</td>\n      <td>331.893494</td>\n      <td>281.143646</td>\n    </tr>\n    <tr>\n      <th>2013-03-31</th>\n      <td>263.750000</td>\n      <td>80.001541</td>\n      <td>242.123825</td>\n      <td>183.926468</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2018-10-26</th>\n      <td>39.116250</td>\n      <td>62.064590</td>\n      <td>51.340519</td>\n      <td>53.530777</td>\n    </tr>\n    <tr>\n      <th>2018-10-27</th>\n      <td>46.711250</td>\n      <td>99.087975</td>\n      <td>102.818413</td>\n      <td>99.458435</td>\n    </tr>\n    <tr>\n      <th>2018-10-28</th>\n      <td>70.970417</td>\n      <td>89.584068</td>\n      <td>102.818413</td>\n      <td>94.906242</td>\n    </tr>\n    <tr>\n      <th>2018-10-29</th>\n      <td>64.495417</td>\n      <td>83.401169</td>\n      <td>92.461655</td>\n      <td>91.614349</td>\n    </tr>\n    <tr>\n      <th>2018-10-30</th>\n      <td>59.041250</td>\n      <td>65.464226</td>\n      <td>65.841728</td>\n      <td>65.735146</td>\n    </tr>\n  </tbody>\n</table>\n<p>2044 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_full = pd.concat([test_df_copy, test_pred1, test_pred2, test_pred3], axis=1)\n",
    "test_df_full = test_df_full.reset_index(drop=True)\n",
    "test_df_full = test_df_full.set_index('Date')\n",
    "test_df_full.to_csv(\"/Users/datou/PycharmProjects/model/JianyangSta/JY_ensemble/data/JY_XGBoost1Test.csv\")\n",
    "train_df_full = pd.concat([train_df_copy, train_pred1, train_pred2, train_pred3], axis=1)\n",
    "train_df_full = train_df_full.reset_index(drop=True)\n",
    "train_df_full = train_df_full.set_index('Date')\n",
    "train_df_full.to_csv(\"/Users/datou/PycharmProjects/model/JianyangSta/JY_ensemble/data/JY_XGBoost1Train.csv\")\n",
    "test_df_full"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T10:15:14.708136Z",
     "start_time": "2024-03-22T10:15:14.688794Z"
    }
   },
   "id": "c0ec365ed0ce39c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
